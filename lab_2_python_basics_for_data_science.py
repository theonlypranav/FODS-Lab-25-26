# -*- coding: utf-8 -*-
"""Lab_2_Python_Basics_for_Data_Science.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1duk7mFBZk8fODxRTACzF2D7lghb922A7

# Lab 2 — Python Tools/Libraries (NumPy, Pandas, Matplotlib, scikit-learn)

**Learning Objectives:**
1) Manipulate arrays with **NumPy**
2) Load & clean data using **Pandas**
3) Visualize with **Matplotlib**
4) Train a tiny model with **scikit-learn** (bridge to your Linear Regression lab)

**Dataset used:** `Apartment.csv`
"""

# Imports Libraries
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score

"""## 1) NumPy essentials
Why NumPy matters: ML libraries store data as **arrays/tensors**. NumPy teaches you shapes, vectorization, and indexing.
"""

a = np.array([1, 2, 3, 4, 5])
print('a:', a)
print('shape:', a.shape)
print('dtype:', a.dtype)

b = np.array([[1, 2, 3], [4, 5, 6]])
print('\nb:\n', b)
print('shape:', b.shape)

# indexing
print('a[0]=', a[0])
print('a[1:4]=', a[1:4])
print('b[0,2]=', b[0,2])

# vectorized operations
print('\na + 10 =', a + 10)
print('a * 2 =', a * 2)
print('mean(a)=', a.mean())
print('std(a)=', a.std())

"""### Broadcasting
Broadcasting lets arrays of different shapes work together.
"""

X = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]])
col_means = X.mean(axis=0)   # (3,)
print('X:\n', X)
print('col_means:', col_means)
print('\nX - col_means (broadcasted):\n', X - col_means)

"""## 2) Pandas essentials (DataFrames)
This is how you load CSVs and prepare features/labels for ML models.
"""

import os

csv_path = '/content/Apartment.csv'
if os.path.exists(csv_path):
    df = pd.read_csv(csv_path)
else:
    # fallback (in case file isn't uploaded)
    df = pd.DataFrame({
        'area': [250, 310, 180, 400, 275],
        'distance': [5.2, 3.8, 7.0, 2.5, 4.1],
        'price': [450, 520, 320, 610, 480]
    })

print('Shape:', df.shape)
df.head()

"""### Basic operations: select, filter, describe"""

print(df.describe())

# selecting columns
area = df['area']
print('\narea head:', area.head().to_list())

# filtering rows
near = df[df['distance'] < df['distance'].median()]
print('\nRows with distance below median:', near.shape[0])

"""### Missing values
Let’s simulate and handle missing values.
"""

df2 = df.copy()
# simulate a couple of missing values
if df2.shape[0] >= 3:
    df2.loc[0, 'area'] = np.nan
    df2.loc[2, 'distance'] = np.nan

print(df2.isna().sum())

# option 1: fill missing with column mean
filled = df2.copy()
filled['area'] = filled['area'].fillna(filled['area'].mean())
filled['distance'] = filled['distance'].fillna(filled['distance'].mean())
print('\nAfter fill:')
print(filled.isna().sum())

"""## 3) Matplotlib essentials
Scatter plots help you understand relationships (e.g., price vs area).
"""

plt.figure()
plt.scatter(df['area'], df['price'])
plt.title('Price vs Area')
plt.xlabel('Area')
plt.ylabel('Price')
plt.grid(True)
plt.show()

"""## 4) Mini ML pipeline (bridge to Linear Regression lab)
We will predict **price** from **area** and **distance** using scikit-learn.

Later, in your Linear Regression lab, you will implement the math (closed-form / gradient descent).
"""

# Features (X) and target (y)
X = df[['area', 'distance']]
y = df['price']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
model = LinearRegression()
model.fit(X_train, y_train)

# Predict
y_pred = model.predict(X_test)

print('Coefficients:', model.coef_)
print('Intercept:', model.intercept_)
print('MSE:', mean_squared_error(y_test, y_pred))
print('R2:', r2_score(y_test, y_pred))

"""### Visual check: actual vs predicted"""

plt.figure()
plt.scatter(y_test, y_pred)
plt.title('Actual vs Predicted')
plt.xlabel('Actual price')
plt.ylabel('Predicted price')
plt.grid(True)

# reference line y=x
mn = min(y_test.min(), y_pred.min())
mx = max(y_test.max(), y_pred.max())
plt.plot([mn, mx], [mn, mx])
plt.show()

"""## Practice Question
**A.** Load `housing.csv` (if you have it) and:
- print `df.info()`
- count missing values
- plot a histogram of `median_house_value`

**B.** Try a **single feature** model using only `area` and compare MSE with the 2-feature model.

**C.** Create a new feature `rooms_per_household` in housing dataset and check if it improves performance.
"""